{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4daff98a-fb13-4da3-9cb0-b738afa63a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f065e77-a41c-443f-94a0-ebc175af0f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_prompt = \"you are an assistant who writes python code based on the prompt. try to keep the code as short and accurate as possible. Add comment for each line to explain the function.\"\n",
    "system_prompt += \"if user faces any issue at any step of the code then only give a 2 - 3 test code for checking the functionality.\"\n",
    "system_prompt += \"If you don't understand the question ask the user to rewrite a better prompt to make you understand the issue\"\n",
    "system_prompt += \"Mention your understanding in the start of your response so that user understands what you interpreted his message. do not add how it works\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "766cdecd-ce35-445d-81ab-f0211b946871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]+[{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    stream = openai.chat.completions.create(model=\"qwen2.5-coder\", messages=messages, stream=True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "05bd194f-dd42-44dc-afe0-1edc0042053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\" # ensuring dark theme!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a79b4f63-cdd0-42d5-b4d3-b91d83c2a101",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7880\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7880/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "gr.ChatInterface(fn=chat, type=\"messages\", js=force_dark_mode, description=\"### ðŸ¤– Python Pro\").launch(pwa=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ffb808-5c9a-4f0c-a3a6-5fa16113753a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207f162-e036-4b3e-bbe8-3297bd241c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
